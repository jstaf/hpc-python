<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head lang="en-us">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
	<meta name="description" content="Writing analysis pipelines with Python">
	<meta name="generator" content="Hugo 0.25.1" />
	
	<title>Snakemake &mdash; HPC Python</title>
	
	<link rel="stylesheet" href="https://jstaf.github.io/hpc-python/css/alabaster.css" type="text/css" />
	<link rel="stylesheet" href="https://jstaf.github.io/hpc-python/css/highlight.css" type="text/css" />

	

	<link rel="shortcut icon" href="https://jstaf.github.io/hpc-python/favicon.ico" type="image/x-icon"/>
</head>

	<body role="document">
		<div class="document">
			<div class="documentwrapper">
				<div class="bodywrapper">
					<div class="body" role="main">
						
	<h1>Snakemake</h1>
	
	

<p>Let&rsquo;s imagine that we&rsquo;re interested in
testing Zipf&rsquo;s Law in some of our favorite books.</p>

<h2 id="zipf-s-law">Zipf&rsquo;s Law</h2>

<p>The most frequently-occurring word occurs approximately twice as
often as the second most frequent word. This is [Zipf&rsquo;s Law][zipfs-law].
{: .callout}</p>

<p>We&rsquo;ve compiled our raw data i.e. the books we want to analyze
and have prepared several Python scripts that together make up our
analysis pipeline.</p>

<p>Let&rsquo;s take quick look at one of the books using the command <code>head books/isles.txt</code>.</p>

<p>Our directory has the Python scripts and data files we
we will be working with:</p>

<pre><code>|- books
|  |- abyss.txt
|  |- isles.txt
|  |- last.txt
|  |- LICENSE_TEXTS.md
|  |- sierra.txt
|- plotcount.py
|- wordcount.py
|- zipf_test.py
</code></pre>

<p>The first step is to count the frequency of each word in a book.</p>

<pre><code>python wordcount.py books/isles.txt isles.dat
</code></pre>

<p>Let&rsquo;s take a quick peek at the result.</p>

<pre><code>head -5 isles.dat
</code></pre>

<p>This shows us the top 5 lines in the output file:</p>

<pre><code>the 3822 6.7371760973
of 2460 4.33632998414
and 1723 3.03719372466
to 1479 2.60708619778
a 1308 2.30565838181
</code></pre>

<p>We can see that the file consists of one row per word.
Each row shows the word itself, the number of occurrences of that
word, and the number of occurrences as a percentage of the total
number of words in the text file.</p>

<p>We can do the same thing for a different book:</p>

<pre><code>python wordcount.py books/abyss.txt abyss.dat
head -5 abyss.dat
</code></pre>

<pre><code>the 4044 6.35449402891
and 2807 4.41074795726
of 1907 2.99654305468
a 1594 2.50471401634
to 1515 2.38057825267
</code></pre>

<p>Let&rsquo;s visualize the results.
The script <code>plotcount.py</code> reads in a data file and plots the 10 most
frequently occurring words as a text-based bar plot:</p>

<pre><code>python plotcount.py isles.dat ascii
</code></pre>

<pre><code>the   ########################################################################
of    ##############################################
and   ################################
to    ############################
a     #########################
in    ###################
is    #################
that  ############
by    ###########
it    ###########
</code></pre>

<p><code>plotcount.py</code> can also show the plot graphically:</p>

<pre><code>python plotcount.py isles.dat show
</code></pre>

<p>Close the window to exit the plot.</p>

<p><code>plotcount.py</code> can also create the plot as an image file (e.g. a PNG file):</p>

<pre><code>python plotcount.py isles.dat isles.png
</code></pre>

<p>Finally, let&rsquo;s test Zipf&rsquo;s law for these books:</p>

<pre><code>python zipf_test.py abyss.dat isles.dat
</code></pre>

<pre><code>Book	First	Second	Ratio
abyss	4044	2807	1.44
isles	3822	2460	1.55
</code></pre>

<p>So we&rsquo;re not too far off from Zipf&rsquo;s law.</p>

<p>Together these scripts implement a common workflow:</p>

<ol>
<li>Read a data file.</li>
<li>Perform an analysis on this data file.</li>
<li>Write the analysis results to a new file.</li>
<li>Plot a graph of the analysis results.</li>
<li>Save the graph as an image, so we can put it in a paper.</li>
<li>Make a summary table of the analyses</li>
</ol>

<p>Running <code>wordcount.py</code> and <code>plotcount.py</code> at the shell prompt, as we
have been doing, is fine for one or two files. If, however, we had 5
or 10 or 20 text files,
or if the number of steps in the pipeline were to expand, this could turn into
a lot of work.
Plus, no one wants to sit and wait for a command to finish, even just for 30
seconds.</p>

<p>The most common solution to the tedium of data processing is to write
a shell script that runs the whole pipeline from start to finish.</p>

<p>Using your text editor of choice (e.g. nano), add the following to a new file named
<code>run_pipeline.sh</code>.</p>

<pre><code># USAGE: bash run_pipeline.sh
# to produce plots for isles and abyss
# and the summary table for the Zipf's law tests

python wordcount.py books/isles.txt isles.dat
python wordcount.py books/abyss.txt abyss.dat

python plotcount.py isles.dat isles.png
python plotcount.py abyss.dat abyss.png

# Generate summary table
python zipf_test.py abyss.dat isles.dat &gt; results.txt
</code></pre>

<p>Run the script and check that the output is the same as before:</p>

<pre><code>bash run_pipeline.sh
cat results.txt
</code></pre>

<p>This shell script solves several problems in computational reproducibility:</p>

<ol>
<li>It explicitly documents our pipeline,
making communication with colleagues (and our future selves) more efficient.</li>
<li>It allows us to type a single command, <code>bash run_pipeline.sh</code>, to
reproduce the full analysis.</li>
<li>It prevents us from <em>repeating</em> typos or mistakes.
You might not get it right the first time, but once you fix something
it&rsquo;ll stay fixed.</li>
</ol>

<p>Despite these benefits it has a few shortcomings.</p>

<p>Let&rsquo;s adjust the width of the bars in our plot produced by <code>plotcount.py</code>.</p>

<p>Edit <code>plotcount.py</code> so that the bars are 0.8 units wide instead of 1 unit.
(Hint: replace <code>width = 1.0</code> with <code>width = 0.8</code> in the definition of
<code>plot_word_counts</code>.)</p>

<p>Now we want to recreate our figures.
We <em>could</em> just <code>bash run_pipeline.sh</code> again.
That would work, but it could also be a big pain if counting words takes
more than a few seconds.
The word counting routine hasn&rsquo;t changed; we shouldn&rsquo;t need to recreate
those files.</p>

<p>Alternatively, we could manually rerun the plotting for each word-count file.
(Experienced shell scripters can make this easier on themselves using a
for-loop.)</p>

<pre><code>for book in abyss isles; do
    python plotcount.py $book.dat $book.png
done
</code></pre>

<p>With this approach, however,
we don&rsquo;t get many of the benefits of having a shell script in the first place.</p>

<p>Another popular option is to comment out a subset of the lines in
<code>run_pipeline.sh</code>:</p>

<pre><code># USAGE: bash run_pipeline.sh
# to produce plots for isles and abyss
# and the summary table for the Zipf's law tests

# These lines are commented out because they don't need to be rerun.
#python wordcount.py books/isles.txt isles.dat
#python wordcount.py books/abyss.txt abyss.dat

python plotcount.py isles.dat isles.png
python plotcount.py abyss.dat abyss.png

# This line is also commented out because it doesn't need to be rerun.
python zipf_test.py abyss.dat isles.dat &gt; results.txt
</code></pre>

<p>Then, we would run our modified shell script using <code>bash run_pipeline.sh</code>.</p>

<p>But commenting out these lines, and subsequently uncommenting them,
can be a hassle and source of errors in complicated pipelines.</p>

<p>What we really want is an executable <em>description</em> of our pipeline that
allows software to do the tricky part for us:
figuring out what steps need to be rerun.</p>

<h2 id="next-section-sm-snakefiles"><a href="../sm-snakefiles/">Next section</a></h2>



						
					</div>
				</div>
			</div>
			
			<div class="sphinxsidebar" role="navigation" aria-label="main navigation">
	<div class="sphinxsidebarwrapper">
		<p class="logo">
			<a href="https://jstaf.github.io/hpc-python/">
				<img class="logo" src="https://jstaf.github.io/hpc-python/favicon.ico" alt="Logo"/>
				<h1 class="logo logo-name">HPC Python</h1>
			</a>
		</p>
		
		<p class="blurb">Writing analysis pipelines with Python</p>

		

	

	

	
		

		

<h3>Navigation</h3>
<ul>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/">Pipelining with Python</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/basics/">Basic syntax</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/scripts/">Scripts and imports</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/lists/">Lists and arrays</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/dicts/">Storing data with dicts</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/functions/">Functional programming</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/profiling/">Measuring code speed</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/performance/">Common performance optimizations</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/parallel/">Running code in parallel</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-intro/">Snakemake</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-snakefiles/">Snakefiles</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-wildcards/">Wildcards</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-patterns/">Pattern Rules</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-python/">Pipelines as Python code</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-resources/">Resources and parallelism</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-logging/">Logging</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-cluster/">Scaling across a cluster</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-final-notes/">Final notes</a>
	</li>
	
</ul>


		

	</div>
</div>
<div class="clearer"></div>
</div>
			<div class="footer">
	&copy; 2017 <a href="https://github.com/jstaf">Jeff Stafford</a>
	|
	Powered by <a href="http://gohugo.io/">Hugo 0.25.1</a>
	&amp; <a href="https://github.com/digitalcraftsman/hugo-alabaster-theme">Alabaster</a>
	
</div>




			

			<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
			<script>hljs.initHighlightingOnLoad();</script>
			

			
		</div>
	</body>
</html>