<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head lang="en-us">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
	<meta name="description" content="Writing analysis pipelines with Python">
	<meta name="generator" content="Hugo 0.24.1" />
	
	<title>Resources and parallelism &mdash; HPC Python</title>
	
	<link rel="stylesheet" href="https://jstaf.github.io/hpc-python/css/alabaster.css" type="text/css" />
	<link rel="stylesheet" href="https://jstaf.github.io/hpc-python/css/highlight.css" type="text/css" />

	

	<link rel="shortcut icon" href="https://jstaf.github.io/hpc-python/favicon.ico" type="image/x-icon"/>
</head>

	<body role="document">
		<div class="document">
			<div class="documentwrapper">
				<div class="bodywrapper">
					<div class="body" role="main">
						
	<h1>Resources and parallelism</h1>
	
	

<p>After the excercises at the end of our last lesson,
our Snakefile looks something like this:</p>

<pre><code># our zipf analysis pipeline
DATS = glob_wildcards('books/{book}.txt').book

rule all:
    input:
        'zipf_analysis.tar.gz'

# delete everything so we can re-run things
rule clean:
    shell:  
        '''
        rm -rf results dats plots
        rm -f results.txt zipf_analysis.tar.gz
        '''

# count words in one of our &quot;books&quot;
rule count_words:
    input: 	
        wc='wordcount.py',
        book='books/{file}.txt'
    output: 'dats/{file}.dat'
    shell: 	'python {input.wc} {input.book} {output}'

# create a plot for each book
rule make_plot:
    input:
        plotcount='plotcount.py',
        book='dats/{file}.dat'
    output: 'plots/{file}.png'
    shell:  'python {input.plotcount} {input.book} {output}'

# generate summary table
rule zipf_test:
    input:  
        zipf='zipf_test.py',
        books=expand('dats/{book}.dat', book=DATS)
    output: 'results.txt'
    shell:  'python {input.zipf} {input.books} &gt; {output}'

# create an archive with all of our results
rule make_archive:
    input:
        expand('plots/{book}.png', book=DATS),
        expand('dats/{book}.dat', book=DATS),
        'results.txt'
    output: 'zipf_analysis.tar.gz'
    shell: 'tar -czvf {output} {input}'
</code></pre>

<p>At this point, we have a complete data analysis pipeline.
Very cool.
But how do we make it run as efficiently as possible?</p>

<h2 id="running-in-parallel">Running in parallel</h2>

<p>Up to this point, Snakemake has printed out an interesting message
whenever we run our pipeline.</p>

<pre><code>Provided cores: 1
Rules claiming more threads will be scaled down.
</code></pre>

<p>So far, Snakemake has been run with one core.
Let&rsquo;s scale up our pipeline to run in parallel.
The only change we need to make is run Snakemake with the <code>-j</code> argument.
<code>-j</code> is used to indicate number of CPU cores available,
and on a cluster, maximum number of jobs (we&rsquo;ll get to that part later).</p>

<pre><code>snakemake clean
snakemake -j 4    # 4 cores is usually a safe assumption when working on a laptop/desktop
</code></pre>

<pre><code>Provided cores: 4
Rules claiming more threads will be scaled down.
# more output follows
</code></pre>

<p>Our pipeline ran in parallel and finished roughly 4 times as quickly!
The takeaway here is that all we need to do to scale from a
serial pipeline is run <code>snakemake</code> with the <code>-j</code> option.</p>

<div class="admonition note">
<p class="first admonition-title">How many CPUs does your computer have?</p>
<p>Now that we can have our pipeline use multiple CPUs,
how do we know how many CPUs to provide to the <code>-j</code> option?
Note that for all of these options, it&rsquo;s best to use CPU cores,
and not CPU threads.</p>

<p><strong>Linux</strong> - You can use the <code>lscpu</code> command.</p>

<p><strong>All platforms</strong> - Python&rsquo;s <code>psutil</code> module can be used to fetch the number of cores in your computer.
Using <code>logical=False</code> returns the number of true CPU cores.
<code>logical=True</code> gives the number of CPU threads on your system.</p>

<pre><code>import psutil
psutil.cpu_count(logical=False)
</code></pre>
</p>
</div>

<h2 id="managing-cpus">Managing CPUs</h2>

<p>Each rule has a number of optional keywords aside from the usual
<code>input</code>, <code>output</code>, and <code>shell</code>/<code>run</code>.
The <code>threads</code> keyword is used to specify how many CPU cores a rule
needs while executing.
Though in reality CPU threads are not quite the same as CPU cores,
the two terms are interchangeable when working with Snakemake.</p>

<p>Let&rsquo;s pretend that our <code>count_words</code> rule is actually very CPU-intensive.
We&rsquo;ll say that it needs a whopping 4 CPUs per run.
We can specify this with the <code>threads</code> keyword in our rule.
We will also modify the rule to print out the number of threads it thinks it is using.
Please note that just giving something 4 threads in Snakemake does not make it run in parallel!
In this case <code>wordcount.py</code> is actually still running with 1 core,
we are simply using it as a demonstration of how to go about
running something with multiple cores.</p>

<pre><code>rule count_words:
    input: 	
        wc='wordcount.py',
        book='books/{file}.txt'
    output: 'dats/{file}.dat'
    threads: 4
    shell:
        '''
        echo &quot;Running {input.wc} with {threads} cores.&quot;
        python {input.wc} {input.book} {output}
        '''
</code></pre>

<p>Now, when we run <code>snakemake -j 4</code>, the <code>count_words</code> rules are run one at a time,
so as to give each execution the resources it needs.
All of our other rules will still run in parallel.
Unless otherwise specified with <code>{threads}</code>, rules will use 1 core by default.</p>

<pre><code>Provided cores: 4
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	4	count_words
	1	make_archive
	4	make_plot
	1	zipf_test
	11

rule count_words:
    input: wordcount.py, books/last.txt
    output: dats/last.dat
    jobid: 3
    wildcards: file=last
    threads: 4

Running wordcount.py with 4 cores.
Finished job 3.
1 of 11 steps (9%) done

# other output follows
</code></pre>

<p>What happens when we don&rsquo;t have 4 cores available?
What if we tell Snakemake to run with 2 cores instead?</p>

<pre><code>snakemake -j 2
</code></pre>

<pre><code>Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	4	count_words
	1	make_archive
	4	make_plot
	1	zipf_test
	11

rule count_words:
    input: wordcount.py, books/last.txt
    output: dats/last.dat
    jobid: 6
    wildcards: file=last
    threads: 2

Running wordcount.py with 2 cores.
Finished job 6.
1 of 11 steps (9%) done

# more output below
</code></pre>

<p>The key bit of output is <code>Rules claiming more threads will be scaled down.</code>.
When Snakemake doesn&rsquo;t have enough cores to run a rule (as defined by <code>{threads}</code>),
Snakemake will run that rule with the maximum available number of cores instead.
After all, Snakemake&rsquo;s job is to get our workflow done.
It automatically scales our workload to match the maximum number of cores available
without us editing the Snakefile.</p>

<h2 id="chaining-multiple-commands">Chaining multiple commands</h2>

<p>Up until now, all of our commands have fit on one line.
To execute multiple bash commands, the only modification we need to make
is use a Python multiline string (begin and end with <code>'''</code>)</p>

<p>One important addition we should be aware of is the <code>&amp;&amp;</code> operator.
<code>&amp;&amp;</code> is a bash operator that runs commands as part of a chain.
If the first command fails, the remaining steps are not run.
This is more forgiving than bash&rsquo;s default &ldquo;hit an error and keep going&rdquo; behavior.
After all, if the first command failed, it&rsquo;s unlikely the other steps will work.</p>

<pre><code># count words in one of our &quot;books&quot;
rule count_words:
    input: 	
        wc='wordcount.py',
        book='books/{file}.txt'
    output: 'dats/{file}.dat'
    threads: 4
    shell:
        '''
        echo &quot;Running {input.wc} with {threads} cores on {input.book}.&quot; &amp;&amp;
            python {input.wc} {input.book} {output}
        '''
</code></pre>

<h2 id="managing-other-types-of-resources">Managing other types of resources</h2>

<p>Not all compute resources are CPUs.
Examples might include limited amounts of RAM, number of GPUs, database locks,
or perhaps we simply don&rsquo;t want multiple processes writing to the same file at once.
All non-CPU resources are handled using the <code>resources</code> keyword.</p>

<p>For our example, let&rsquo;s pretend that creating a plot with <code>plotcount.py</code>
requires dedicated access to a GPU (it doesn&rsquo;t),
and only one GPU is available.
How do we indicate this to Snakemake so that it knows to give dedicated access to a GPU
for rules that need it?
Let&rsquo;s modify the <code>make_plot</code> rule as an example:</p>

<pre><code># create a plot for each book
rule make_plot:
    input:
        plotcount='plotcount.py',
        book='dats/{file}.dat'
    output: 'plots/{file}.png'
    resources: gpu=1
    shell:  'python {input.plotcount} {input.book} {output}'
</code></pre>

<p>We can execute our pipeline using the following (using 8 cores and 1 gpu):</p>

<pre><code>snakemake clean
snakemake -j 8 --resources gpu=1
</code></pre>

<pre><code>Provided cores: 8
Rules claiming more threads will be scaled down.
Provided resources: gpu=1
# other output removed for brevity
</code></pre>

<p>Resources are entirely arbitrary - like wildcards, they can be named anything.
Snakemake knows nothing about them aside from the fact that they have a name and a value.
In this case <code>gpu</code> indicates simply that there is a resource called <code>gpu</code> used by <code>make_plot</code>.
We provided 1 <code>gpu</code> to the workflow, and the <code>gpu</code> is considered in use as long as the rule is running.
Once the <code>make_plot</code> rule completes, the <code>gpu</code> it consumed is added back to the pool of available <code>gpu</code>s.</p>

<p>But what happens if we run our pipeline without specifying the number of GPUs?</p>

<pre><code>snakemake clean
snakemake -j 8
</code></pre>

<pre><code>Provided cores: 8
Rules claiming more threads will be scaled down.
Unlimited resources: gpu
</code></pre>

<p>If you have specified that a rule needs a certain resource,
but do not specify how many you have,
Snakemake will assume that the resources in question are unlimited.</p>

<h2 id="other-uses-for-resources">Other uses for <code>resources</code></h2>

<p>Resources do not have to correspond to actual compute resources.
Perhaps one rule is particularly I/O heavy,
and it&rsquo;s best if only a limited number of these jobs run at a time.
Or maybe a type of rule uses a lot of network bandwidth as it downloads data.
In all of these cases, <code>resources</code> can be used to constrain access
to arbitrary compute resources so that each rule can run at it&rsquo;s most efficient.
Snakemake will run your rules in such a way as to maximize throughput given your
resource constraints.</p>

<h2 id="next-section-sm-logging"><a href="../sm-logging/">Next section</a></h2>



						
					</div>
				</div>
			</div>
			
			<div class="sphinxsidebar" role="navigation" aria-label="main navigation">
	<div class="sphinxsidebarwrapper">
		<p class="logo">
			<a href="https://jstaf.github.io/hpc-python/">
				<img class="logo" src="https://jstaf.github.io/hpc-python/favicon.ico" alt="Logo"/>
				<h1 class="logo logo-name">HPC Python</h1>
			</a>
		</p>
		
		<p class="blurb">Writing analysis pipelines with Python</p>

		

	

	

	
		

		

<h3>Navigation</h3>
<ul>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/">Pipelining with Python</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/basics/">Basic syntax</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/scripts/">Scripts and imports</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/lists/">Lists and arrays</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/dicts/">Storing data with dicts</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/functions/">Functional programming</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/profiling/">Measuring code speed</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/performance/">Common performance optimizations</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/parallel/">Running code in parallel</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-intro/">Snakemake</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-snakefiles/">Snakefiles</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-wildcards/">Wildcards</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-patterns/">Pattern Rules</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-python/">Pipelines as Python code</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-resources/">Resources and parallelism</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-logging/">Logging</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-cluster/">Scaling across a cluster</a>
	</li>
	
	<li class="toctree-l1">
		<a class="reference internal" href="/hpc-python/sm-final-notes/">Final notes</a>
	</li>
	
</ul>


		

	</div>
</div>
<div class="clearer"></div>
</div>
			<div class="footer">
	&copy; 2017 <a href="https://github.com/jstaf">Jeff Stafford</a>
	|
	Powered by <a href="http://gohugo.io/">Hugo 0.24.1</a>
	&amp; <a href="https://github.com/digitalcraftsman/hugo-alabaster-theme">Alabaster</a>
	
</div>




			

			<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.3.0/highlight.min.js"></script>
			<script>hljs.initHighlightingOnLoad();</script>
			

			
		</div>
	</body>
</html>